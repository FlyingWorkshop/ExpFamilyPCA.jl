# Deriving the EPCA Objective Function

In this section, we demonstrate how the EPCA objective function and the decompression function $g$ can be derived using different combinations of mathematical components. This flexibility allows for efficient and adaptable implementations of EPCA in Julia.

## The Regularized EPCA Objective

Recall from the [introduction](./intro.md) that the regularized EPCA objective aims to minimize the following expression:

```math
B_{F}(X \| g(\Theta)) + \epsilon B_{F}(\mu \| g(\Theta)).
```

where:

*  $B_F$ is the Bregman divergence generated by a convex and continuously differentiable function $F$,
*  $F$ is the convex conjugate of $G$,
*  $G$ is the log-parition function (or any convex function),
*  $g$ is the link function,
*  $X$ is the data matrix,
*  $\Theta$ is the parameter matrix, and
*  $\mu \in \mathrm{range}(g)$ and $\epsilon > 0$ are regularization parameters.

Our goal is to show that both $B_F$ and $g$ can be induced from various base components, namely $F$, $G$, $f$ and $g$. This allows for multiple pathways to define and compute the EPCA objective in Julia.

## Different Approaches to Specifying the EPCA Objective and Decompression

### 1. Using $F$ and $f$

We begin by showing that the convex function $F$ and the link function $g$ are sufficient to define the EPCA objective. The Bregman divergence $B_F(X \| g(\Theta))$ can be expressed as

```math
\begin{aligned}
B_F(X \| g(\Theta)) &= F(X) - F(g(\Theta)) - f(g(\Theta))(X - g(\Theta)) \\
&= F(X) - F(g(\Theta)) - \Theta(X - g(\Theta))
\end{aligned}
```

where the second line follows from the relationship $f = g^{-1}$ (see the [appendix](./appendix/inverses.md)) and $\Theta = f(g(\Theta))$. Thus, specifying $F$ and $g$ is sufficient to fully describe the EPCA objective and decompression.

### 2. Using $F$ and $f$

Since $g$ can be recovered from $f$ (the inverse of $g$), we can also derive the EPCA objective using $F$ and $f$. Given that $g$ is strictly increasing (as $G$, the conjugate of $F$, is strictly convex and differentiable), we can compute $g$ numerically.

To evaluate $g(a)$ for any $a$ in the domain of $g$, we solve for $x$ in the equation $f(x) = a$. Since $f$ and $g$ are monotone, we can effeciently solve for $x$ by finding the unique root of $f(a) - x$ using a binary search. Therefore, the EPCA objective can also be specified using only $F$ and $f$.

### 3. Using $F$ Alone

Julia's multiple dispatch system promotes high levels of generic code reuse [dispatch](@cite). This means that by defining the convex function $F$, we can leverage packages like 
[`Symbolics.jl`](https://symbolics.juliasymbolics.org/stable/) [symbolics](@cite) to symbolically differentiate $F$ and obtain its derivative $f = F'$. Using the same procedure as above, we can then evaluate $g$ from $f$.

Because multiple dispatch allows functions and operations to be defined on top of base Julia atoms, the symbolic expressions returned by `Symbolics.jl` can seamlessly integrate with entirely separate packages like [`Optim.jl`](https://julianlsolvers.github.io/Optim.jl/stable/) [optim](@cite) to optimize the EPCA objective. Therefore, by defining $F$ alone, we can induce all necessary components to specify and compute the EPCA objective and decompression.

### 4. Using $G$ and $g$

Alternatively, we can express the EPCA objective using the log-partition function $G$ and the link function $g$. Starting from the previous dervition (and dropping the constant), we have:

```math
\begin{aligned}
-F(g(\Theta)) - \Theta(X - G(\Theta)) &= G(\Theta) - g(\Theta) \Theta - \Theta(X - G(\Theta)) \\
&= G(\Theta) - \Theta X
\end{aligned}
```

This shows that the EPCA objective simplifies to the negative log-likelihood $G(\Theta) - \Theta X$. Therefore, $G$ and $g$ are sufficient to define the EPCA objecitve and link function.

### 5. Using $G$ Alone

Since $g$ is the derivative of $G$ (i.e., $g = G'$), we can now recover $g$ directly from $G$ via symbolic differentiation. This means that providing $G$ alone is enough to specify both the EPCA objective and the link function $g$.

### 6. Using $B_F$ and $g$

If we already have the Bregman divergence $B_F$ and the link function $g$, specifying the EPCA objective is trivial.

### 7. Using $\tilde{B}$ and $g$

Similarly, using the transformed Bregman divergence $\tilde{B}(p, q) = B_F(p \| g(q))$ along with $g$ is straightforward. Given that $\tilde{B}$ is just $B_F$ evaluated at $g(q)$, and we already have the link function $g$, defining the EPCA objective is almost too obvious to mention. While mathematically uninteresting, this specification is useful in practice to avoid domain errors that make optimization difficult with certain exponential family members (e.g., gamma, negative binomial, Pareto).

## Conclusion

In summary, the EPCA objective function and the decompression function $g$ can be derived from various components. The flexibility afforded by Julia's multiple dispatch and symbolic differentiation capabilities allows for efficient computation of EPCA in different scenarios. Depending on the form of the data and the problem at hand, one can choose the most convenient set of components to define and compute the EPCA objective.

